{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae60af40-dfce-4878-b9c4-e87447ee255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch.nn.utils.rnn\n",
    "\n",
    "df_train = pd.read_csv('arithmetic_train.csv')\n",
    "df_eval = pd.read_csv('arithmetic_eval.csv')\n",
    "\n",
    "df_train[\"tgt\"] = df_train[\"tgt\"].apply(lambda x:str(x))\n",
    "df_train[\"src\"] = df_train[\"src\"].add(df_train[\"tgt\"])\n",
    "df_train[\"len\"] = df_train[\"src\"].apply(lambda x: len(x))\n",
    "\n",
    "df_eval[\"tgt\"] = df_eval[\"tgt\"].apply(lambda x:str(x))\n",
    "df_eval[\"src\"] = df_eval[\"src\"].add(df_eval[\"tgt\"])\n",
    "df_eval[\"len\"] = df_eval[\"src\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "#TODO1\n",
    "char_to_id = {'<pad>': 0, '<eos>': 1}\n",
    "id_to_char = {0: '<pad>', 1: '<eos>'}\n",
    "\n",
    "# 添加数字0到9的映射\n",
    "for i in range(10):\n",
    "    char_to_id[str(i)] = i + 2\n",
    "    id_to_char[i + 2] = str(i)\n",
    "\n",
    "# 添加符号的映射\n",
    "symbols = ['+', '-', '*', '(', ')', '=']\n",
    "for idx, symbol in enumerate(symbols, start=len(char_to_id)):\n",
    "    char_to_id[symbol] = idx\n",
    "    id_to_char[idx] = symbol\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "\n",
    "df_train = df_train.drop(df_train.columns[0], axis=1)\n",
    "df_eval = df_eval.drop(df_eval.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e869a5db-e28e-45b8-84dc-a513feef2748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "      <th>char_id_list</th>\n",
       "      <th>label_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[3, 6, 14, 15, 6, 5, 12, 4, 2, 16, 17, 10, 10,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 4, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[15, 8, 12, 3, 16, 14, 7, 17, 5, 7, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[3, 5, 12, 5, 4, 12, 4, 11, 17, 9, 6, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 6, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[5, 3, 14, 15, 5, 13, 3, 3, 16, 17, 13, 4, 6, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 4, 6, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>[4, 6, 14, 6, 11, 12, 3, 17, 3, 3, 9, 9, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 9, 9, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              src  tgt  len  \\\n",
       "0  14*(43+20)=882    0   14   \n",
       "1      (6+1)*5=35    0   10   \n",
       "2     13+32+29=74    0   11   \n",
       "3  31*(3-11)=-248    0   14   \n",
       "4    24*49+1=1177    0   12   \n",
       "\n",
       "                                        char_id_list  \\\n",
       "0  [3, 6, 14, 15, 6, 5, 12, 4, 2, 16, 17, 10, 10,...   \n",
       "1             [15, 8, 12, 3, 16, 14, 7, 17, 5, 7, 1]   \n",
       "2           [3, 5, 12, 5, 4, 12, 4, 11, 17, 9, 6, 1]   \n",
       "3  [5, 3, 14, 15, 5, 13, 3, 3, 16, 17, 13, 4, 6, ...   \n",
       "4        [4, 6, 14, 6, 11, 12, 3, 17, 3, 3, 9, 9, 1]   \n",
       "\n",
       "                                     label_id_list  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 4, 1]  \n",
       "1                [0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 1]  \n",
       "2             [0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 6, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 4, 6, 10, 1]  \n",
       "4          [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 9, 9, 1]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO2\n",
    "def process_dataframe(df):\n",
    "    # 新增兩個欄位\n",
    "    df['char_id_list'] = None\n",
    "    df['label_id_list'] = None\n",
    "    # 逐行處理 df_train\n",
    "    for i in range(len(df)):\n",
    "        char = []\n",
    "        e_id = 0\n",
    "        for j in range(len(df[\"src\"][i])):\n",
    "            # 將 src 中的字元轉換為對應的 id\n",
    "            char.append(char_to_id[df[\"src\"][i][j]])\n",
    "            # 如果遇到對應 id 為 17，記錄其位置\n",
    "            if char_to_id[df[\"src\"][i][j]] == 17:\n",
    "                e_id = j\n",
    "        # 將 1 添加到 char 列表末尾\n",
    "        char = char + [1]\n",
    "        # 更新 label_id_list 和 char_id_list 欄位\n",
    "        df.at[i, 'char_id_list'] = char\n",
    "        df.at[i, 'label_id_list'] = [0]*(e_id+1) + char[e_id+1:]\n",
    "        \n",
    "    df['tgt'] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "# 呼叫函式\n",
    "df_train = process_dataframe(df_train)\n",
    "df_eval = process_dataframe(df_eval)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34303c55-5c3c-4e9c-8a60-66fe23753744",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "lr = 0.001\n",
    "grad_clip = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a928cb7e-7948-409c-a325-9e1d23c6d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences):\n",
    "       \n",
    "        self.sequences = sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        seq = self.sequences.loc[index, \"char_id_list\"]\n",
    "        end_idx = seq.index(17)  # 找到字符 `=` 的索引位置\n",
    "        start_idx = len(seq) - end_idx -2\n",
    "        x =  seq[:end_idx + 1] + [0]*start_idx\n",
    "        y = [0]* (end_idx) + seq[end_idx+1:]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_x = [torch.tensor(data[0]) for data in batch]\n",
    "    batch_y = [torch.tensor(data[1]) for data in batch]\n",
    "    batch_x_lens = torch.LongTensor([len(x) for x in batch_x])\n",
    "    batch_y_lens = torch.LongTensor([len(y) for y in batch_y])\n",
    "    \n",
    "    # Pad the input sequence\n",
    "    pad_batch_x = torch.nn.utils.rnn.pad_sequence(batch_x,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    pad_batch_y = torch.nn.utils.rnn.pad_sequence(batch_y,\n",
    "                                                  batch_first=True,\n",
    "                                                  padding_value=char_to_id['<pad>'])\n",
    "    \n",
    "    return pad_batch_x, pad_batch_y, batch_x_lens, batch_y_lens\n",
    "\n",
    "\n",
    "\n",
    "ds_train = Dataset(df_train[['char_id_list', 'label_id_list']])\n",
    "ds_eval = Dataset(df_eval[['char_id_list', 'label_id_list']])\n",
    "\n",
    "\n",
    "# Build dataloader of train set and eval set, collate_fn is the collate function\n",
    "dl_train = DataLoader(Dataset(df_train), batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "dl_eval = DataLoader(Dataset(df_eval), batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe2afc2-c27f-4b1d-8696-7a1cd6e9eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                            embedding_dim=embed_dim,\n",
    "                                            padding_idx=char_to_id['<pad>'])\n",
    "        \n",
    "        self.rnn_layer1 = torch.nn.LSTM(input_size=embed_dim,\n",
    "                                        hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.rnn_layer2 = torch.nn.LSTM(input_size=hidden_dim,\n",
    "                                        hidden_size=hidden_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.linear = torch.nn.Sequential(torch.nn.Linear(in_features=hidden_dim,\n",
    "                                                          out_features=hidden_dim),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Linear(in_features=hidden_dim,\n",
    "                                                          out_features=vocab_size))\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_lens):\n",
    "        return self.encoder(batch_x, batch_x_lens)\n",
    "    \n",
    "    # The forward pass of the model\n",
    "    def encoder(self, batch_x, batch_x_lens):\n",
    "        batch_x = self.embedding(batch_x)\n",
    "        \n",
    "        batch_x = torch.nn.utils.rnn.pack_padded_sequence(batch_x,\n",
    "                                                          batch_x_lens,\n",
    "                                                          batch_first=True,\n",
    "                                                          enforce_sorted=False)\n",
    "        \n",
    "        batch_x, _ = self.rnn_layer1(batch_x)\n",
    "        batch_x, _ = self.rnn_layer2(batch_x)\n",
    "        \n",
    "        batch_x, _ = torch.nn.utils.rnn.pad_packed_sequence(batch_x,\n",
    "                                                            batch_first=True)\n",
    "        \n",
    "        batch_x = self.linear(batch_x)\n",
    "        \n",
    "        return batch_x\n",
    "    \n",
    "    def generator(self, start_char, max_len=200):\n",
    "        \n",
    "        char_list = [char_to_id[c] for c in start_char]\n",
    "        \n",
    "        next_char = None\n",
    "        hidden1 = (torch.zeros(1, 1, hidden_dim).to(\"cpu\"), \n",
    "               torch.zeros(1, 1, hidden_dim).to(\"cpu\"))\n",
    "        hidden2 = (torch.zeros(1, 1, hidden_dim).to(\"cpu\"), \n",
    "               torch.zeros(1, 1, hidden_dim).to(\"cpu\"))\n",
    "    \n",
    "        while len(char_list) < max_len: \n",
    "            # Write your code here \n",
    "            # Pack the char_list to tensor\n",
    "            input_tensor = torch.tensor(char_list).unsqueeze(0).to(\"cpu\")\n",
    "            # Input the tensor to the embedding layer, LSTM layers, linear respectively\n",
    "            embedded = self.embedding(input_tensor)\n",
    "            out, hidden1 = self.rnn_layer1(embedded, hidden1)\n",
    "            out, hidden2 = self.rnn_layer2(out, hidden2)\n",
    "            \n",
    "            y = self.linear(out[:, -1, :]) \n",
    "            # Get the predicted character ID by taking the argmax of the output probabilities\n",
    "            next_char = torch.argmax(y, dim=-1).item()\n",
    "         \n",
    "            if next_char == char_to_id['<eos>']:\n",
    "                break\n",
    "            \n",
    "            char_list.append(next_char)\n",
    "            \n",
    "        return [id_to_char[ch_id] for ch_id in char_list]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b540dd1f-61fa-49eb-8206-ab7044db8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CharRNN(vocab_size,\n",
    "                embed_dim,\n",
    "                hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a839acc-e5ea-49bc-8607-1dd8f03a4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████| 37020/37020 [1:30:31<00:00,  6.82it/s, loss=0.49] \n",
      "Validation epoch 1: 100%|██████████| 4114/4114 [05:14<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35661918328584996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 37020/37020 [1:30:25<00:00,  6.82it/s, loss=0.466]\n",
      "Validation epoch 2: 100%|██████████| 4114/4114 [04:20<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4694548907882241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "i = 0\n",
    "for epoch in range(1, epochs+1):\n",
    "    # The process bar\n",
    "    bar = tqdm(dl_train, desc=f\"Train epoch {epoch}\")\n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        # Clear the gradient\n",
    "        optimizer.zero_grad()\n",
    "        batch_pred_y = model(batch_x.to(device), batch_x_lens)\n",
    "        batch_pred_y = batch_pred_y.view(-1, batch_pred_y.size(-1))  \n",
    "        batch_y = batch_y.view(-1)\n",
    "       \n",
    "        # Input the prediction and ground truths to loss function\n",
    "        loss = criterion(batch_pred_y, batch_y.to(device))\n",
    "        \n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), grad_clip) # gradient clipping\n",
    "\n",
    "        # Optimize parameters in the model\n",
    "        optimizer.step()\n",
    "\n",
    "        i+=1\n",
    "        if i%50==0:\n",
    "            bar.set_postfix(loss = loss.item())\n",
    "    \n",
    "    # Evaluate your model\n",
    "    bar = tqdm(dl_eval, desc=f\"Validation epoch {epoch}\")\n",
    "    matched = 0\n",
    "    total = 0\n",
    "    for batch_x, batch_y, batch_x_lens, batch_y_lens in bar:\n",
    "        \n",
    "        predictions = model(batch_x.to(device), batch_x_lens)\n",
    "        \n",
    "        # Convert predictions to the predicted class labels\n",
    "        pred_labels = torch.argmax(predictions, dim=-1)\n",
    "        \n",
    "        batch_y = batch_y.to(device)\n",
    "        # Check whether the prediction matches the ground truths\n",
    "        for i in range(batch_y.size(0)):\n",
    "            total += 1        \n",
    "            mask = batch_y[i] != 0  \n",
    "            # Check if the entire sequence matches (exact match)\n",
    "            if torch.equal(pred_labels[i, mask], batch_y[i, mask]):\n",
    "                matched += 1\n",
    "\n",
    "    print(matched/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a63b5c95-98a2-4669-a287-3ad334f2463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+2=3134566791119911111991119191119191919191919191919191919191919191919191919911919191919191919191919191919191918181818181818181989919119991119181819191818181891919191991191919199119911991191991199119\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "print(\"\".join(model.generator(\"1+2=\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f85e9-f69f-4662-b476-7352a817a23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
